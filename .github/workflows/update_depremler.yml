name: Update Deprem Data

on:
  schedule:
    - cron: "*/5 * * * *" # her 5 dakikada bir
  workflow_dispatch:       # manuel tetikleme

jobs:
  update-depremler:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: false  # token commit edilmesin

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas beautifulsoup4 PyGithub

      - name: Fetch Kandilli data and update JSON
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python - << 'EOF'
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
import os
from datetime import datetime
from github import Github

REPO_NAME = "bedirhan327/deprem-veri-collector"
FILE_PATH = "public/data/deprem_data.json"
MAX_RECORDS = 1000

# Kandilli veri çek
url = "http://www.koeri.boun.edu.tr/scripts/lst0.asp"
response = requests.get(url)
response.encoding = "utf-8"
soup = BeautifulSoup(response.text, "html.parser")
lines = soup.find("pre").get_text().split("\n")

data = []
for line in lines[7:]:
    parts = line.split()
    if len(parts) >= 9:
        tarih = parts[0]
        saat = parts[1]
        enlem = float(parts[2])
        boylam = float(parts[3])
        derinlik = float(parts[4])
        ml = parts[6] if parts[6] != "-.-" else None
        yer = " ".join(parts[8:-1])
        cozum = parts[-1]
        data.append({"Tarih": tarih, "Saat": saat, "Enlem": enlem, "Boylam": boylam, 
                     "Derinlik": derinlik, "ML": ml, "Yer": yer, "Cozum": cozum})

df_new = pd.DataFrame(data)

# Eski JSON varsa oku
if os.path.exists(FILE_PATH):
    with open(FILE_PATH, "r", encoding="utf-8") as f:
        try:
            old_data = json.load(f)
            df_old = pd.DataFrame(old_data)
        except Exception as e:
            print("Eski JSON okunamadı:", e)
            df_old = pd.DataFrame()
else:
    df_old = pd.DataFrame()

# Birleştir ve duplicate temizle
df_combined = pd.concat([df_old, df_new], ignore_index=True)
df_combined.drop_duplicates(subset=["Tarih", "Saat", "Enlem", "Boylam"], inplace=True)
df_combined.sort_values(by=["Tarih", "Saat"], ascending=False, inplace=True)

# Limit
df_limited = df_combined.head(MAX_RECORDS)

# JSON kaydet
os.makedirs(os.path.dirname(FILE_PATH), exist_ok=True)
with open(FILE_PATH, "w", encoding="utf-8") as f:
    f.write(df_limited.to_json(orient="records", force_ascii=False, indent=2))

# GitHub push
try:
    g = Github(os.environ["GITHUB_TOKEN"])
    repo = g.get_repo(REPO_NAME)
    try:
        file = repo.get_contents(FILE_PATH)
        repo.update_file(FILE_PATH, f"Auto update {datetime.now()}", 
                         df_limited.to_json(orient="records", force_ascii=False, indent=2),
                         file.sha, branch="main")
        print("✅ JSON dosyası güncellendi ve pushlandı.")
    except Exception:
        repo.create_file(FILE_PATH, f"First upload {datetime.now()}", 
                         df_limited.to_json(orient="records", force_ascii=False, indent=2),
                         branch="main")
        print("✅ JSON dosyası oluşturuldu ve pushlandı.")
except Exception as e:
    print("❌ GitHub push sırasında hata:", e)
EOF
